
import os
from typing import Dict, List, Any
from dotenv import load_dotenv
from langchain.prompts import ChatPromptTemplate
from data.repositories.FaissVectorRepository import VectorRepository
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferWindowMemory
from LLM.model_via_openrouter import OpenRouterChat
import logging
load_dotenv()

class RAGService:
    """RAG Service: FAISS + OpenRouterChat + Memory + Citations."""
    
    def __init__(
        self,
        faiss_path: str = "vector_index/faiss_index",
        top_k: int = 3,
        memory_k: int = 5,
        verbose: bool = False
    ):
        # 1. LLM
        self.llm = OpenRouterChat()
        
        # 2. Vector DB
        self.repo = VectorRepository()
        self.embeddings = self.repo.embeddings
        self.vectorstore = self.repo.vectorstore
        self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": top_k})
        
        # 3. Memory
        self.memory = ConversationBufferWindowMemory(
            memory_key="chat_history",
            return_messages=True,
            k=memory_k,
            input_key="question",
            output_key="answer"
        )
        
        # 4. Prompt (Ä‘Ãºng format cho ConversationalRetrievalChain)
        self.prompt = ChatPromptTemplate.from_template(
            """
System: DÃ¹ng context Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c. Náº¿u cÃ³ thÃ´ng tin, hÃ£y trÃ­ch dáº«n [arxiv_id] á»Ÿ cuá»‘i cÃ¢u. Náº¿u khÃ´ng biáº¿t, tráº£ lá»i: "KhÃ´ng tÃ¬m tháº¥y info." Tráº£ lá»i ngáº¯n gá»n, dÆ°á»›i 3 cÃ¢u.

Context: {context}

Chat History: {chat_history}

Human: {question}

Assistant: 
            """
        )
        
        # 5. RAG Chain (KHÃ”NG dÃ¹ng input_key/output_key - Ä‘Ã£ bá»‹ loáº¡i bá»)
        self.chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.retriever,
            memory=self.memory,
            combine_docs_chain_kwargs={"prompt": self.prompt},
            verbose=verbose,
            return_source_documents=True
        )
        
        
        print(f"âœ… RAGService ready! FAISS: {faiss_path}, Top-K: {top_k}")
    
    def chat(self, question: str) -> Dict[str, Any]:
        """
        Chat RAG: question â†’ answer + sources + citations.
        
        Returns:
            {
                'answer': str,
                'sources': List[Dict],
                'chat_history': List
            }
        """
        # Gá»i chain
        result = self.chain({"question": question})
        self.debug_retrieve(question)
        # Láº¥y source documents
        source_docs = result.get("source_documents", [])

        # TrÃ­ch xuáº¥t sources
        sources = [
            {
                "text": doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content,
                "metadata": doc.metadata
            }
            for doc in source_docs
        ]
        
        # TrÃ­ch dáº«n arxiv_id (náº¿u cÃ³)
        arxiv_ids = []
        arxiv_urls = []
        for doc in source_docs:
            arxiv_id = doc.metadata.get("title")
            arxiv_url = doc.metadata.get("url")
            if arxiv_id:
                arxiv_ids.append(arxiv_id)
                arxiv_urls.append(arxiv_url)
        
        # ThÃªm trÃ­ch dáº«n vÃ o answer
        answer = result["answer"].strip()
        if arxiv_ids:
            answer += "\n\nTrÃ­ch dáº«n: " + ", ".join(f"[{aid}]" for aid in arxiv_ids)
        elif not answer.lower().__contains__("khÃ´ng tÃ¬m tháº¥y"):
            answer += "\n\n[KhÃ´ng cÃ³ trÃ­ch dáº«n kháº£ dá»¥ng]"
        
        return {
            "answer": answer,
            "sources": sources,
            "chat_history": self.memory.chat_memory.messages
        }
    def debug_retrieve(self, question: str):
        """Tráº£ vá» list (doc, score) Ä‘á»ƒ xem rÃµ threshold."""
        docs_with_scores = self.vectorstore.similarity_search_with_score(
            question,
            k=self.retriever.search_kwargs.get("k", 3)
        )
        
        print("\nðŸ” DEBUG SCORES:")
        for i, (doc, score) in enumerate(docs_with_scores, start=1):
            print(f"\n--- Result {i} ---")
            print(f"Score: {1/(1+score)}")
            print(f"Metadata: {doc.metadata}")
            print(f"Content: {doc.page_content[:200]}...")
        
        return docs_with_scores
    def clear_history(self):
        """XÃ³a lá»‹ch sá»­ chat."""
        self.memory.clear()
        print("ðŸ§¹ Chat history cleared")
    
    def get_stats(self) -> Dict[str, Any]:
        """Láº¥y stats."""
        return {
            "faiss_path": self.repo.db_path,
            "vector_count": len(self.vectorstore.index_to_docstore_id),
            "top_k": self.retriever.search_kwargs.get("k"),
            "memory_k": self.memory.k,
            "chat_history_length": len(self.memory.chat_memory.messages)
        }